{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81fb74-6528-4a7e-b058-7bb7634a7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ransomhouse(json_data, days):\n",
    "    \"\"\"Filtra as entradas com actionDate dentro dos últimos 'days' dias.\"\"\"\n",
    "\n",
    "    # Definindo a data limite\n",
    "    hoje = datetime.now()\n",
    "    dias_atras = hoje - timedelta(days=days)\n",
    "\n",
    "    filtered_data = []\n",
    "    \n",
    "    for entry in json_data.get('data', []):\n",
    "        # Verifica se a chave 'actionDate' existe\n",
    "        if 'actionDate' in entry:\n",
    "            date_str = entry['actionDate']\n",
    "            \n",
    "            # Verificar se a string não está vazia\n",
    "            if date_str:\n",
    "                # Converter a string da data para um objeto datetime\n",
    "                try:\n",
    "                    date_obj = datetime.strptime(date_str, '%d/%m/%Y')\n",
    "                    # Verificar se a data está dentro do intervalo\n",
    "                    if dias_atras <= date_obj <= hoje:\n",
    "                        filtered_data.append({\n",
    "                            'header': entry.get('header', ''),\n",
    "                            'url': entry.get('url', ''),\n",
    "                            'actionDate': date_str\n",
    "                        })\n",
    "                except ValueError:\n",
    "                    # Ignorar se a data não for válida\n",
    "                    continue\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a079ad8-41c7-48d3-bd31-59ca06c12007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def monti(html_content, dias):\n",
    "    # Criando um objeto BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Inicializando a lista de resultados\n",
    "    results = []\n",
    "\n",
    "    # Definindo o limite de datas (D-7)\n",
    "    hoje = datetime.now()\n",
    "    limite = hoje - timedelta(days=dias)\n",
    "\n",
    "    # Encontrando todas as divs com a classe 'col-auto published'\n",
    "    divs = soup.find_all('div', class_='col-auto published')\n",
    "    \n",
    "    # Iterando sobre as divs e verificando se a data é válida\n",
    "    for div in divs:\n",
    "        try:\n",
    "            # Convertendo o texto da div para uma data\n",
    "            data_texto = div.text.strip()\n",
    "            \n",
    "            # Ajuste o formato para incluir horas, minutos e segundos\n",
    "            data_publicacao = datetime.strptime(data_texto, '%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            # Verificando se a data está dentro do intervalo (últimos D-7 dias)\n",
    "            if limite <= data_publicacao <= hoje:\n",
    "                # Encontrando o título anterior à div\n",
    "                h5 = div.find_previous('h5')\n",
    "                title = h5.text.strip() if h5 else 'Título não encontrado'\n",
    "                \n",
    "                # Adicionando o título e a data à lista de resultados\n",
    "                results.append({'title': title, 'date': data_texto})\n",
    "        except ValueError as e:\n",
    "            # Ignorar se o valor não for uma data válida, mas logar para depuração\n",
    "            print(f\"Erro ao converter data: {data_texto}. Erro: {e}\")\n",
    "            continue\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e830685-4828-471c-8535-0a0b00fc7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(html_content, days):\n",
    "    # Criando um objeto BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Data atual e data de corte para 7 dias atrás\n",
    "    current_date = datetime.now()\n",
    "    cutoff_date = current_date - timedelta(days)\n",
    "\n",
    "    # Coletando os dados\n",
    "    data_rows = []\n",
    "\n",
    "    for th in soup.find_all('th', class_='News'):\n",
    "        # Título é o texto do th, excluindo as tags filhas\n",
    "        title = th.contents[0].strip()  # Apenas o texto do <th> antes do <div>\n",
    "\n",
    "        # Encontrando o link\n",
    "        link_div = th.find('i', class_='link')\n",
    "        link = link_div.next_sibling.strip() if link_div and link_div.next_sibling else None\n",
    "        \n",
    "        # Encontrando a data de publicação\n",
    "        publication_date_div = th.find(string=lambda text: text and 'publication date:' in text)\n",
    "        publication_date = publication_date_div.strip().split(':')[-1].strip() if publication_date_div else None\n",
    "        \n",
    "        # Verificando se a data de publicação está nos últimos 7 dias\n",
    "        if publication_date:\n",
    "            pub_date = datetime.strptime(publication_date, '%Y-%m-%d')\n",
    "            if pub_date >= cutoff_date:  # Apenas incluir se a data de publicação for maior ou igual à data de corte\n",
    "                data_rows.append({'title': title, 'link': link, 'publication_date': publication_date})\n",
    "\n",
    "    return data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306dbfc-5ba0-48fa-94e9-5a1c523ec4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handala(html_content, dias):\n",
    "    # Fazendo o parsing do HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Definindo o limite de datas (D-7)\n",
    "    hoje = datetime.now()\n",
    "    limite = hoje - timedelta(days=dias)\n",
    "\n",
    "    # Coletando informações\n",
    "    results = []\n",
    "    for li in soup.find_all('li', class_='wp-block-post'):\n",
    "        title = li.find('h2').find('a').text\n",
    "        time_tag = li.find('time')\n",
    "        \n",
    "        if time_tag:\n",
    "            date = time_tag.get('datetime').split('T')[0]  # Pegando apenas a data\n",
    "            date_obj = datetime.strptime(date, '%Y-%m-%d')\n",
    "\n",
    "            # Verificando se a data está dentro do intervalo dos últimos D-7 dias\n",
    "            if limite <= date_obj <= hoje:\n",
    "                description = li.find('p', class_='wp-block-post-excerpt__excerpt').text\n",
    "                \n",
    "                # Extraindo o site da descrição\n",
    "                site_match = re.search(r'\\b(?:https?://|www\\.)?([\\w.-]+(?:\\.[a-z]{2,}))\\b', description)\n",
    "                site = site_match.group(0) if site_match else None\n",
    "                \n",
    "                # Adicionando os resultados\n",
    "                results.append({\n",
    "                    'title': title,\n",
    "                    'date': date,\n",
    "                    'site': site\n",
    "                })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6de3e-fce4-4033-b903-816a98d9977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def blackbyte(html, days):\n",
    "    # Parsear o HTML\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # Obter o nome da empresa (caption)\n",
    "    nome_empresa = soup.find('caption', class_='target-name').get_text()\n",
    "\n",
    "    # Obter todas as tags <td> que contêm datas\n",
    "    datas_td = soup.find_all('td')\n",
    "    \n",
    "    # Lista para armazenar os dicionários de resultados\n",
    "    resultados = []\n",
    "    \n",
    "    # Definir o intervalo de datas (últimos 7 dias)\n",
    "    hoje = datetime.now()\n",
    "    limite = hoje - timedelta(days)\n",
    "    \n",
    "    # Iterar sobre as datas e verificar se estão dentro do intervalo\n",
    "    for td in datas_td:\n",
    "        try:\n",
    "            # Tentar converter o texto da tag <td> para datetime\n",
    "            data = datetime.strptime(td.get_text(), '%Y-%m-%d %H:%M')\n",
    "            \n",
    "            # Se a data for nos últimos 7 dias, adicionar ao resultado\n",
    "            if limite <= data <= hoje:\n",
    "                resultados.append({\n",
    "                    \"empresa\": nome_empresa,\n",
    "                    \"data\": td.get_text()\n",
    "                })\n",
    "        except ValueError:\n",
    "            # Ignorar se o valor não for uma data válida\n",
    "            continue\n",
    "\n",
    "    # Retornar a lista de dicionários\n",
    "    return resultados\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
